{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yabsera-e/Crop-Segmentation-Yield-Estimation/blob/main/Crop_Segmentation_%2B_Yield_Estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vm4X5srKFJ3",
        "outputId": "728662ad-fa76-4400-cb98-7fa5a66fa0d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting patchify\n",
            "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.7/dist-packages (from patchify) (1.21.5)\n",
            "Installing collected packages: patchify\n",
            "Successfully installed patchify-0.2.3\n"
          ]
        }
      ],
      "source": [
        "pip install patchify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vgNaINSKP1-",
        "outputId": "7f19bf28-4879-4ba3-d661-346dad06ca5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting segmentation_models\n",
            "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Collecting image-classifiers==1.0.0\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting efficientnet==1.0.0\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.18.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.21.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.2.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.6.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.15.0)\n",
            "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install segmentation_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt7-6cBeKVbL",
        "outputId": "e101c5f6-691e-4765-b186-facd0a24561f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Segmentation Models: using `keras` framework.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from patchify import patchify, unpatchify\n",
        "from PIL import Image\n",
        "import segmentation_models as sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcY9F0a-KqDi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.signal\n",
        "from tqdm import tqdm\n",
        "\n",
        "import gc\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import matplotlib.pyplot as plt\n",
        "    PLOT_PROGRESS = True\n",
        "else:\n",
        "    PLOT_PROGRESS = False\n",
        "def _spline_window(window_size, power=2):\n",
        "    intersection = int(window_size/4)\n",
        "    wind_outer = (abs(2*(scipy.signal.triang(window_size))) ** power)/2\n",
        "    wind_outer[intersection:-intersection] = 0\n",
        "\n",
        "    wind_inner = 1 - (abs(2*(scipy.signal.triang(window_size) - 1)) ** power)/2\n",
        "    wind_inner[:intersection] = 0\n",
        "    wind_inner[-intersection:] = 0\n",
        "\n",
        "    wind = wind_inner + wind_outer\n",
        "    wind = wind / np.average(wind)\n",
        "    return wind\n",
        "\n",
        "\n",
        "cached_2d_windows = dict()\n",
        "def _window_2D(window_size, power=2):\n",
        "    \"\"\"\n",
        "    Make a 1D window function, then infer and return a 2D window function.\n",
        "    Done with an augmentation, and self multiplication with its transpose.\n",
        "    Could be generalized to more dimensions.\n",
        "    \"\"\"\n",
        "    # Memoization\n",
        "    global cached_2d_windows\n",
        "    key = \"{}_{}\".format(window_size, power)\n",
        "    if key in cached_2d_windows:\n",
        "        wind = cached_2d_windows[key]\n",
        "    else:\n",
        "        wind = _spline_window(window_size, power)\n",
        "        wind = np.expand_dims(np.expand_dims(wind, 1), 1)      \n",
        "        wind = wind * wind.transpose(1, 0, 2)\n",
        "        if PLOT_PROGRESS:\n",
        "            # For demo purpose, let's look once at the window:\n",
        "            plt.imshow(wind[:, :, 0], cmap=\"viridis\")\n",
        "            plt.title(\"2D Windowing Function for a Smooth Blending of \"\n",
        "                      \"Overlapping Patches\")\n",
        "            plt.show()\n",
        "        cached_2d_windows[key] = wind\n",
        "    return wind\n",
        "\n",
        "\n",
        "def _pad_img(img, window_size, subdivisions):\n",
        "    \"\"\"\n",
        "    Add borders to img for a \"valid\" border pattern according to \"window_size\" and\n",
        "    \"subdivisions\".\n",
        "    Image is an np array of shape (x, y, nb_channels).\n",
        "    \"\"\"\n",
        "    aug = int(round(window_size * (1 - 1.0/subdivisions)))\n",
        "    more_borders = ((aug, aug), (aug, aug), (0, 0))\n",
        "    ret = np.pad(img, pad_width=more_borders, mode='reflect')\n",
        "    # gc.collect()\n",
        "\n",
        "    if PLOT_PROGRESS:\n",
        "        # For demo purpose, let's look once at the window:\n",
        "        plt.imshow(ret)\n",
        "        plt.title(\"Padded Image for Using Tiled Prediction Patches\\n\"\n",
        "                  \"(notice the reflection effect on the padded borders)\")\n",
        "        plt.show()\n",
        "    return ret\n",
        "\n",
        "\n",
        "def _unpad_img(padded_img, window_size, subdivisions):\n",
        "    aug = int(round(window_size * (1 - 1.0/subdivisions)))\n",
        "    ret = padded_img[\n",
        "        aug:-aug,\n",
        "        aug:-aug,\n",
        "        :\n",
        "    ]\n",
        "    # gc.collect()\n",
        "    return ret\n",
        "\n",
        "\n",
        "def _rotate_mirror_do(im):\n",
        "    mirrs = []\n",
        "    mirrs.append(np.array(im))\n",
        "    mirrs.append(np.rot90(np.array(im), axes=(0, 1), k=1))\n",
        "    mirrs.append(np.rot90(np.array(im), axes=(0, 1), k=2))\n",
        "    mirrs.append(np.rot90(np.array(im), axes=(0, 1), k=3))\n",
        "    im = np.array(im)[:, ::-1]\n",
        "    mirrs.append(np.array(im))\n",
        "    mirrs.append(np.rot90(np.array(im), axes=(0, 1), k=1))\n",
        "    mirrs.append(np.rot90(np.array(im), axes=(0, 1), k=2))\n",
        "    mirrs.append(np.rot90(np.array(im), axes=(0, 1), k=3))\n",
        "    return mirrs\n",
        "\n",
        "\n",
        "def _rotate_mirror_undo(im_mirrs):\n",
        "    origs = []\n",
        "    origs.append(np.array(im_mirrs[0]))\n",
        "    origs.append(np.rot90(np.array(im_mirrs[1]), axes=(0, 1), k=3))\n",
        "    origs.append(np.rot90(np.array(im_mirrs[2]), axes=(0, 1), k=2))\n",
        "    origs.append(np.rot90(np.array(im_mirrs[3]), axes=(0, 1), k=1))\n",
        "    origs.append(np.array(im_mirrs[4])[:, ::-1])\n",
        "    origs.append(np.rot90(np.array(im_mirrs[5]), axes=(0, 1), k=3)[:, ::-1])\n",
        "    origs.append(np.rot90(np.array(im_mirrs[6]), axes=(0, 1), k=2)[:, ::-1])\n",
        "    origs.append(np.rot90(np.array(im_mirrs[7]), axes=(0, 1), k=1)[:, ::-1])\n",
        "    return np.mean(origs, axis=0)\n",
        "\n",
        "\n",
        "def _windowed_subdivs(padded_img, window_size, subdivisions, nb_classes, pred_func):\n",
        "\n",
        "    WINDOW_SPLINE_2D = _window_2D(window_size=window_size, power=2)\n",
        "\n",
        "    step = int(window_size/subdivisions)\n",
        "    padx_len = padded_img.shape[0]\n",
        "    pady_len = padded_img.shape[1]\n",
        "    subdivs = []\n",
        "\n",
        "    for i in range(0, padx_len-window_size+1, step):\n",
        "        subdivs.append([])\n",
        "        for j in range(0, pady_len-window_size+1, step):            \n",
        "            patch = padded_img[i:i+window_size, j:j+window_size, :]\n",
        "            subdivs[-1].append(patch)\n",
        "\n",
        "    # Here, `gc.collect()` clears RAM between operations.\n",
        "    # It should run faster if they are removed, if enough memory is available.\n",
        "    gc.collect()\n",
        "    subdivs = np.array(subdivs)\n",
        "    gc.collect()\n",
        "    a, b, c, d, e = subdivs.shape\n",
        "    subdivs = subdivs.reshape(a * b, c, d, e)\n",
        "    gc.collect()\n",
        "\n",
        "    subdivs = pred_func(subdivs)\n",
        "    gc.collect()\n",
        "    subdivs = np.array([patch * WINDOW_SPLINE_2D for patch in subdivs])\n",
        "    gc.collect()\n",
        "\n",
        "    # Such 5D array:\n",
        "    subdivs = subdivs.reshape(a, b, c, d, nb_classes)\n",
        "    gc.collect()\n",
        "\n",
        "    return subdivs\n",
        "\n",
        "\n",
        "def _recreate_from_subdivs(subdivs, window_size, subdivisions, padded_out_shape):\n",
        "    \"\"\"\n",
        "    Merge tiled overlapping patches smoothly.\n",
        "    \"\"\"\n",
        "    step = int(window_size/subdivisions)\n",
        "    padx_len = padded_out_shape[0]\n",
        "    pady_len = padded_out_shape[1]\n",
        "\n",
        "    y = np.zeros(padded_out_shape)\n",
        "\n",
        "    a = 0\n",
        "    for i in range(0, padx_len-window_size+1, step):\n",
        "        b = 0\n",
        "        for j in range(0, pady_len-window_size+1, step):                #SREENI: Changed padx to pady (Bug in original code)\n",
        "            windowed_patch = subdivs[a, b]\n",
        "            y[i:i+window_size, j:j+window_size] = y[i:i+window_size, j:j+window_size] + windowed_patch\n",
        "            b += 1\n",
        "        a += 1\n",
        "    return y / (subdivisions ** 2)\n",
        "\n",
        "\n",
        "def predict_img_with_smooth_windowing(input_img, window_size, subdivisions, nb_classes, pred_func):\n",
        " \n",
        "    pad = _pad_img(input_img, window_size, subdivisions)\n",
        "    pads = _rotate_mirror_do(pad)\n",
        "\n",
        "    res = []\n",
        "    for pad in tqdm(pads):\n",
        "        # For every rotation:\n",
        "        sd = _windowed_subdivs(pad, window_size, subdivisions, nb_classes, pred_func)\n",
        "        one_padded_result = _recreate_from_subdivs(\n",
        "            sd, window_size, subdivisions,\n",
        "            padded_out_shape=list(pad.shape[:-1])+[nb_classes])\n",
        "\n",
        "        res.append(one_padded_result)\n",
        "\n",
        "    # Merge after rotations:\n",
        "    padded_results = _rotate_mirror_undo(res)\n",
        "\n",
        "    prd = _unpad_img(padded_results, window_size, subdivisions)\n",
        "\n",
        "    prd = prd[:input_img.shape[0], :input_img.shape[1], :]\n",
        "\n",
        "    if PLOT_PROGRESS:\n",
        "        #plt.imshow(prd)\n",
        "        plt.title(\"Smoothly Merged Patches that were Tiled Tighter\")\n",
        "        plt.show()\n",
        "    return prd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "nzIe0hIcRt1M",
        "outputId": "b24e712b-9750-4054-8e06-88a816a4ef80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting anvil-uplink\n",
            "  Downloading anvil_uplink-0.3.41-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (1.15.0)\n",
            "Collecting argparse\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (0.16.0)\n",
            "Collecting ws4py\n",
            "  Downloading ws4py-0.5.1.tar.gz (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 172 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ws4py\n",
            "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ws4py: filename=ws4py-0.5.1-py3-none-any.whl size=45229 sha256=d4be0f5f79b828ce72704cc28f369a7c82e85efc1477fa6bbd14950d6cc881ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/ea/7d/3410aa0aa0e4402ead9a7a97ab2214804887e0f5c2b76f0c96\n",
            "Successfully built ws4py\n",
            "Installing collected packages: ws4py, argparse, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.3.41 argparse-1.4.0 ws4py-0.5.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Default environment\" as SERVER\n"
          ]
        }
      ],
      "source": [
        "!pip install anvil-uplink\n",
        "import anvil.server\n",
        "anvil.server.connect(\"546KKBRHUSGJR43CJ6QC3U4V-UNCR4I4B36R6HUJK\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "hjyssA-MMA-Q",
        "outputId": "effb3d2b-812a-4694-b35f-9018622eaee8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nplt.figure(figsize=(12, 12))\\nplt.subplot(221)\\nplt.title('Testing Image')\\nplt.imshow(img)\\nplt.subplot(222)\\nplt.title('Testing Label')\\n#plt.imshow(original_mask)\\nplt.subplot(223)\\nplt.title('Prediction with smooth blending')\\nplt.imshow(final_prediction)\\nplt.show()\\n\""
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@anvil.server.callable\n",
        "def predictor():\n",
        "  from sklearn.preprocessing import MinMaxScaler\n",
        "  scaler = MinMaxScaler()\n",
        "  \n",
        "  #from smooth_tiled_predictions import predict_img_with_smooth_windowing\n",
        "  \n",
        "  BACKBONE = 'resnet34'\n",
        "  preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "  img = cv2.imread(\"/content/drive/MyDrive/ESSTI Project | Crop Yield Estimation/GUI/Uploaded Images/newTempImg.png\") \n",
        "  #img = cv2.imread(\"/content/drive/MyDrive/ESSTI Project | Crop Yield Estimation/GUI/Uploaded Images/newTempImg.png\")  #N-34-66-C-c-4-3.tif, N-34-97-D-c-2-4.tif\n",
        "  input_img = scaler.fit_transform(img.reshape(-1, img.shape[-1])).reshape(img.shape)\n",
        "  input_img = preprocess_input(input_img)\n",
        "  from keras.models import load_model\n",
        "  model = load_model(\"/content/drive/MyDrive/ESSTI Project | Crop Yield Estimation/Models/SebilView.hdf5\", compile=False)                \n",
        "  # size of patches\n",
        "  patch_size = 256\n",
        "  # Number of classes \n",
        "  n_classes = 10\n",
        " # img = cv2.imread(\"/content/drive/MyDrive/ESSTI Project | Crop Yield Estimation/GUI/Uploaded Images/temp_img.png\")\n",
        " # img = cv2.imread(\"/content/drive/MyDrive/ESSTI Project | Crop Yield Estimation/GUI/Uploaded Images/newTempImg.png\") \n",
        "  plt.imshow(img)\n",
        "  predictions_smooth = predict_img_with_smooth_windowing(\n",
        "      input_img,\n",
        "      window_size=patch_size,\n",
        "      subdivisions=2,  # Minimal amount of overlap for windowing. Must be an even number.\n",
        "      nb_classes=n_classes,\n",
        "      pred_func=(\n",
        "          lambda img_batch_subdiv: model.predict((img_batch_subdiv))\n",
        "      \n",
        "      )\n",
        "  )\n",
        "\n",
        "  final_prediction = np.argmax(predictions_smooth, axis=2)\n",
        "\n",
        "#Save prediction and original mask for comparison\n",
        "  plt.imsave('/content/drive/MyDrive/ESSTI Project | Crop Yield Estimation/GUI/Predictions/Pred.jpg', final_prediction)\n",
        "  #plt.imshow('/content/drive/MyDrive/ESSTI Project | Crop Yield Estimation/GUI/Uploaded Images/segmented_image.jpg')\n",
        "#plt.imsave('/content/drive/MyDrive/Crop Identification | Satellite_Imagery /Datasets/otiginal.tif_mask.jpg', original_mask)\n",
        "###################\n",
        "\"\"\"\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.subplot(221)\n",
        "plt.title('Testing Image')\n",
        "plt.imshow(img)\n",
        "plt.subplot(222)\n",
        "plt.title('Testing Label')\n",
        "#plt.imshow(original_mask)\n",
        "plt.subplot(223)\n",
        "plt.title('Prediction with smooth blending')\n",
        "plt.imshow(final_prediction)\n",
        "plt.show()\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCr_-eiZrclN"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def estimate():\n",
        "  from PIL import Image\n",
        "  im = Image.open('/content/drive/MyDrive/ESSTI Project | Crop Yield Estimation/GUI/Predictions/Pred.jpg')\n",
        "  violet = 0\n",
        "  blue = 0\n",
        "  lightblue = 0\n",
        "  yellow = 0\n",
        "  green = 0\n",
        "  \n",
        "  for pixel in im.getdata():\n",
        "      if pixel == (68, 0, 83): \n",
        "          violet += 1\n",
        "      elif pixel == (71, 44, 123): \n",
        "          blue += 1\n",
        "      elif pixel == (253, 230, 36): \n",
        "          yellow += 1\n",
        "      elif pixel == (172, 220, 48): \n",
        "          green += 1\n",
        "      elif pixel == (41,174,127):\n",
        "          lightblue += 1\n",
        " \n",
        "  print('violet=' + str(violet)+', blue='+str(blue)+', yellow'+str(yellow)+', green'+str(green))\n",
        "  total_landcover = 1048576\n",
        "  violet_yield = 14.20 #barley\n",
        "  blue_yield = 0        #bare land\n",
        "  green_yield = 17.1     #wheat\n",
        "  yellow_yield = 13      #teff\n",
        "  lightblue_yield = 30.20 #maize\n",
        "\n",
        "  \n",
        "  violet_portion=round((violet/total_landcover)*100,2)\n",
        "  violet_cov = round(violet_portion/100*25,2)\n",
        "  violet_est = round(violet_cov*violet_yield,2)\n",
        "  violet_str = 'Barley'\n",
        "  blue_str = 'Bare Land'\n",
        "  green_str = 'Wheat'\n",
        "  yellow_str = 'Teff'\n",
        "  lightblue_str = 'maize'\n",
        "\n",
        "  blue_portion=round((blue/total_landcover)*100,2)\n",
        "  blue_cov = round(blue_portion/100*25,2)\n",
        "  blue_est = round(blue_cov*blue_yield,2)\n",
        "  blue_str = 'Bare Land'\n",
        "  \n",
        "  yellow_portion=round((yellow/total_landcover)*100,2)\n",
        "  yellow_cov = round(yellow_portion/100*25,2)\n",
        "  yellow_est = round(yellow_cov*yellow_yield,2)\n",
        "  yellow_str = 'Teff'\n",
        "  \n",
        "  green_portion=round((green/total_landcover)*100,2)\n",
        "  green_cov = round(green_portion/100*25,2)\n",
        "  green_est = round(green_cov*green_yield,2)\n",
        "  green_str = 'Wheat'\n",
        "\n",
        "  lightblue_portion=round((lightblue/total_landcover)*100,2)\n",
        "  lightblue_cov = round(lightblue_portion/100*25,2)\n",
        "  lightblue_est = round(lightblue_cov*lightblue_yield,2)\n",
        "  lightblue_str = 'maize'\n",
        "  \n",
        "  total_portion = violet_portion + blue_portion + yellow_portion + green_portion\n",
        "  unidentified = round((100 - total_portion),2)\n",
        "  \n",
        "  print('viloet_portion= '+str(violet_portion)+'\\n'+'blue_portion= '+str(blue_portion)+'\\n'+ 'yellow_portion= '+str(yellow_portion)+'\\n'+'green_portion= '+str(green_portion)+'\\n'+'unidentified_portion= '+str(unidentified))\n",
        "  \n",
        "  return (lightblue_str,lightblue_cov,lightblue_portion,lightblue_est,yellow_str,yellow_cov,yellow_portion,yellow_est,green_str,green_cov,green_portion,green_est,blue_str,blue_cov,blue_portion,blue_est,violet_str,violet_cov,violet_portion,violet_est)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ojmyRDU5R2gT"
      },
      "outputs": [],
      "source": [
        "anvil.server.wait_forever()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Crop Segmentation + Yield Estimation ",
      "provenance": [],
      "mount_file_id": "1u6UqTkvO1e-kgESCvqgwYbQ-vvTR2i9L",
      "authorship_tag": "ABX9TyObwtkn2pfwZYi31LEQkFKm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}